
%=================================Popularity bias in RSSEs=================================
%Such systems can provide a wide range of items, including third-party libraries (TPLs), API function calls, code snippets, or relevant Stack Overflow posts. 

% are preferably provided to users. 
%\textbf{Popularity bias.} 
%Recommender systems are among the most widespread applications of machine learning, playing a significant role in assisting human decision-making processes. The quality of the recommendations %they generate 
%is closely linked to user satisfaction and the interests of the platforms. However, 
Being heavily reliant on data and algorithms, recommender systems can be susceptible to biases that may lead to unfair outcomes, potentially jeoparadizing trust in them. %Consequently, it is imperative to address fairness issues in recommendation scenarios. 
For recommender systems, %the ability to fetch rare but useful items %rarely %seen but useful %, \ie in the \emph{long tail} 
%is deemed to be a desirable feature~\cite{10.1145/1454008.1454012}. %In recommendation, %4688070
the \emph{long tail effect} indicates that a handful of items are extremely popular, whilst most of the remaining ones, so-called the long tail, are not seen by users \cite{Anderson:2006:LTW:1197299}. %Essentially, products belonging to the long tail are considered a social good~\cite{DBLP:conf/recsys/AbdollahpouriMB19} and recommending rare but useful items benefits both customers and shop owners \cite{Vargas_sales_diversity_14}. 
\emph{Popularity bias} is a common phenomenon of general purpose recommender systems~\cite{DBLP:conf/flairs/AbdollahpouriBM19,DBLP:conf/recsys/AbdollahpouriMB19,10.1145/3564284}, \ie providing to users only frequently seen items. Likewise, RSSEs are no exception, while they become more effective in suggesting handy recommendations, RSSEs also suffer from popularity bias by presenting artifacts %that have been 
used by several developers~\cite{10174041}. While this favors artifacts that are possibly more reliable and well-maintained, it would essentially mean that systems fail to recommend some relevant goals, architecture- or solution-specific artifacts. %
%several artifacts are rarely recommended because they are very specific or more recent. %In fact, recommending artifacts in the long tail has been deemed a desired feature of any recommender systems~\cite{10.1145/1454008.1454012}. 
%Thus, popularity bias can be considered as an issue that needs to be tackled.






In our recent work~\cite{10174041}, by means of mixed methods research, \ie performing both a qualitative and quantitative evaluation, we studied popularity bias recommender systems for mining third-party libraries (TPLs). % to study the presence of popularity bias in TPL RSSEs. 
%,MacDonellSKM10,DBLP:conf/ease/Wohlin14
First, following existing guidelines for such type of study software engineering \cite{KitchenhamBLBB11}, we investigated whether state-of-the-art research has already tackled the issue of popularity bias. %The literature analysis, we investigate to what extent the popularity bias in TPL RSSEs has ever been studied by state-of-the-art research. 
Interestingly, the literature review on major software engineering venues reveals that the issue of dealing with popularity bias has not received enough attention from the community. All of the surveyed studies tackled different issues in library recommendation, with the main aim of improving the relevance of the final ranked list, %The empirical study reveals that the issue of dealing with popularity in TPL RSSEs has not received adequate attention from the software engineering community. 
%Among the surveyed work, 
only one work attempts to tackle popularity, unfortunately, it fails to maintain a trade-off between fairness and accuracy. %getting a low recommendation accuracy. 

Then, we performed a quantitative evaluation on \numSys existing TPL RSSEs, exploring their capability to deal with %the recommendation of 
popular artifacts. %Finally, we propose a mechanism to defuse popularity bias in the recommendation list. 
%Though we do not aim for a complete, detailed systematic literature review, .
%The finding is further confirmed with an empirical evaluation on \numSys TPL RSSEs, \ie 
The experiments showed that three among the considered systems provide to developers highly popular TPLs. The remaining system, while being able to lessen the effect of frequent TPLs, suffers from a low accuracy. Altogether, we see that cutting-edge research in software engineering neglects the issue of popularity bias in TPL recommender systems, leaving a research gap that has to be %properly 
bridged.


Our work was positively received by the reviewers, and it was accepted for publication in a CORE Rank A conference\footnote{\url{http://portal.core.edu.au/conf-ranks/?search=MSR&by=all&source=CORE2023&sort=atitle&page=1}} with the following details: %as follows:%with the following details: 
%in the following paper:
%The results of this work have been published in the following paper:
%\vspace{-.1cm}
\begin{itemize}
	\item \small{\underline{Phuong T. Nguyen}, Riccardo Rubei, Juri Di Rocco, Claudio Di Sipio, Davide Di Ruscio, Massimiliano Di Penta ``\emph{Dealing with Popularity Bias in Recommender Systems for Third-party Libraries: How far Are We?}'', in Proceedings of the IEEE/ACM 20th Int. Conf. on Mining Software Repositories (MSR 2023), %Melbourne, Australia, 2023, 
		DOI: \href{https://doi.org/10.1109/MSR59073.2023.00016}{10.1109/MSR59073.20\-23.00016}.}
\end{itemize}


%\vspace{-.4cm}
%As found for \CR, state-of-the-art TPL RSSEs may not properly leverage peculiar aspects of a project, \eg related to implementation solutions. Hence, they fail to recommend some relevant goals, architecture- or solution-specific libraries.

